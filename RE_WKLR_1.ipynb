{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:42.497604Z",
     "iopub.status.busy": "2025-04-18T08:08:42.497062Z",
     "iopub.status.idle": "2025-04-18T08:08:43.165847Z",
     "shell.execute_reply": "2025-04-18T08:08:43.164961Z",
     "shell.execute_reply.started": "2025-04-18T08:08:42.497572Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (351, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to the data file\n",
    "# file_path = '/kaggle/input/ionosphere/ionosphere/ionosphere.data'\n",
    "\n",
    "file_path = 'D:\\\\CSRE\\\\2. Spring 2024\\\\IE 506 Machine Learning\\\\Course Project\\\\Implementation\\\\RE-WKLR\\\\Datasets\\\\ionosphere.csv'\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Show the shape and first few rows\n",
    "print(f\"Shape of the dataset: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:43.192390Z",
     "iopub.status.busy": "2025-04-18T08:08:43.192076Z",
     "iopub.status.idle": "2025-04-18T08:08:43.207089Z",
     "shell.execute_reply": "2025-04-18T08:08:43.205686Z",
     "shell.execute_reply.started": "2025-04-18T08:08:43.192364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Assign column names (optional but helpful)\n",
    "# The dataset has 34 features and 1 label => total 35 columns\n",
    "column_names = [f'feature_{i}' for i in range(34)] + ['label']\n",
    "df.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after encoding: label\n",
      "0    225\n",
      "1    126\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Encode the target label ('g' = good, 'b' = bad)\n",
    "label_mapping = {'g': 0, 'b': 1}  # 'g' → 0 (majority), 'b' → 1 (rare)\n",
    "df['label'] = df['label'].map(label_mapping)\n",
    "print(\"Class distribution after encoding:\", df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:43.222734Z",
     "iopub.status.busy": "2025-04-18T08:08:43.222363Z",
     "iopub.status.idle": "2025-04-18T08:08:43.237864Z",
     "shell.execute_reply": "2025-04-18T08:08:43.236683Z",
     "shell.execute_reply.started": "2025-04-18T08:08:43.222696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Split features and labels\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:43.243619Z",
     "iopub.status.busy": "2025-04-18T08:08:43.243239Z",
     "iopub.status.idle": "2025-04-18T08:08:43.268163Z",
     "shell.execute_reply": "2025-04-18T08:08:43.267121Z",
     "shell.execute_reply.started": "2025-04-18T08:08:43.243590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0          1          0    0.99539   -0.05889    0.85243    0.02306   \n",
       "1          1          0    1.00000   -0.18829    0.93035   -0.36156   \n",
       "2          1          0    1.00000   -0.03365    1.00000    0.00485   \n",
       "3          1          0    1.00000   -0.45161    1.00000    1.00000   \n",
       "4          1          0    1.00000   -0.02401    0.94140    0.06531   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_25  feature_26  \\\n",
       "0    0.83398   -0.37708    1.00000    0.03760  ...    -0.51171     0.41078   \n",
       "1   -0.10868   -0.93597    1.00000   -0.04549  ...    -0.26569    -0.20468   \n",
       "2    1.00000   -0.12062    0.88965    0.01198  ...    -0.40220     0.58984   \n",
       "3    0.71216   -1.00000    0.00000    0.00000  ...     0.90695     0.51613   \n",
       "4    0.92106   -0.23255    0.77152   -0.16399  ...    -0.65158     0.13290   \n",
       "\n",
       "   feature_27  feature_28  feature_29  feature_30  feature_31  feature_32  \\\n",
       "0    -0.46168     0.21266    -0.34090     0.42267    -0.54487     0.18641   \n",
       "1    -0.18401    -0.19040    -0.11593    -0.16626    -0.06288    -0.13738   \n",
       "2    -0.22145     0.43100    -0.17365     0.60436    -0.24180     0.56045   \n",
       "3     1.00000     1.00000    -0.20099     0.25682     1.00000    -0.32382   \n",
       "4    -0.53206     0.02431    -0.62197    -0.05707    -0.59573    -0.04608   \n",
       "\n",
       "   feature_33  label  \n",
       "0    -0.45300      0  \n",
       "1    -0.02447      1  \n",
       "2    -0.38238      0  \n",
       "3     1.00000      1  \n",
       "4    -0.65697      0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:43.269872Z",
     "iopub.status.busy": "2025-04-18T08:08:43.269575Z",
     "iopub.status.idle": "2025-04-18T08:08:43.284463Z",
     "shell.execute_reply": "2025-04-18T08:08:43.283481Z",
     "shell.execute_reply.started": "2025-04-18T08:08:43.269840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Step 4: Check for missing values (optional, but good practice)\n",
    "# print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:43.285849Z",
     "iopub.status.busy": "2025-04-18T08:08:43.285537Z",
     "iopub.status.idle": "2025-04-18T08:08:43.305370Z",
     "shell.execute_reply": "2025-04-18T08:08:43.304453Z",
     "shell.execute_reply.started": "2025-04-18T08:08:43.285813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (351, 34), Shape of labels: (351,)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "# Show shape of final data\n",
    "print(f\"Shape of features: {X_scaled.shape}, Shape of labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:43.306734Z",
     "iopub.status.busy": "2025-04-18T08:08:43.306377Z",
     "iopub.status.idle": "2025-04-18T08:08:43.392921Z",
     "shell.execute_reply": "2025-04-18T08:08:43.391998Z",
     "shell.execute_reply.started": "2025-04-18T08:08:43.306698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # 1. Basic info\n",
    "# print(\"Dataset Info:\")\n",
    "# print(df.info())\n",
    "# print(\"\\nStatistical Summary:\")\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:43.394350Z",
     "iopub.status.busy": "2025-04-18T08:08:43.393956Z",
     "iopub.status.idle": "2025-04-18T08:08:43.545698Z",
     "shell.execute_reply": "2025-04-18T08:08:43.544561Z",
     "shell.execute_reply.started": "2025-04-18T08:08:43.394312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # 2. Class distribution\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.countplot(x='label', data=df)\n",
    "# plt.title('Class Distribution')\n",
    "# plt.xticks([0, 1], ['Good (0)', 'Bad (1)'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:44.301027Z",
     "iopub.status.busy": "2025-04-18T08:08:44.300776Z",
     "iopub.status.idle": "2025-04-18T08:08:44.333529Z",
     "shell.execute_reply": "2025-04-18T08:08:44.332593Z",
     "shell.execute_reply.started": "2025-04-18T08:08:44.301005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:44.334813Z",
     "iopub.status.busy": "2025-04-18T08:08:44.334550Z",
     "iopub.status.idle": "2025-04-18T08:08:44.355169Z",
     "shell.execute_reply": "2025-04-18T08:08:44.354080Z",
     "shell.execute_reply.started": "2025-04-18T08:08:44.334791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split classes for sampling\n",
    "class_0_train = X_train[y_train == 0]\n",
    "class_1_train = X_train[y_train == 1]\n",
    "\n",
    "\n",
    "# Balanced and imbalanced training sets\n",
    "\"\"\"if dataset_name == \"spam\":\n",
    "    X_train_bal = pd.concat([\n",
    "        class_0_train.sample(200, random_state=42),\n",
    "        class_1_train.sample(200, random_state=42)\n",
    "    ])\n",
    "    y_train_bal = y_train.loc[X_train_bal.index]\n",
    "    \n",
    "    X_train_imb = pd.concat([\n",
    "        class_0_train.sample(200, random_state=42),\n",
    "        class_1_train.sample(100, random_state=42)\n",
    "    ])\n",
    "    y_train_imb = y_train.loc[X_train_imb.index]\n",
    "else:\"\"\"\n",
    "X_train_bal = pd.concat([\n",
    "    class_0_train.sample(40, random_state=42),\n",
    "    class_1_train.sample(40, random_state=42)\n",
    "])\n",
    "y_train_bal = y_train.loc[X_train_bal.index]\n",
    "\n",
    "X_train_imb = pd.concat([\n",
    "    class_0_train.sample(40, random_state=42),\n",
    "    class_1_train.sample(15, random_state=42)\n",
    "])\n",
    "y_train_imb = y_train.loc[X_train_imb.index]\n",
    "\n",
    "# Test set rarity — 5% events to non-events ratio (8% for SPECT Heart)\n",
    "class_0_test = X_test[y_test == 0]\n",
    "class_1_test = X_test[y_test == 1]\n",
    "y_0_test = y_test[y_test == 0]\n",
    "y_1_test = y_test[y_test == 1]\n",
    "\n",
    "test_ratio = 0.05 \n",
    "n_test_events = int(round(len(class_0_test) * test_ratio))\n",
    "\n",
    "sampled_class_1 = class_1_test.sample(n_test_events, random_state=42)\n",
    "sampled_y_1 = y_1_test.loc[sampled_class_1.index]\n",
    "\n",
    "X_test_final = pd.concat([class_0_test, sampled_class_1])\n",
    "y_test_final = pd.concat([y_0_test, sampled_y_1])\n",
    "\n",
    "# Shuffle X_test_final and y_test_final together\n",
    "test_final = pd.concat([X_test_final, y_test_final], axis=1).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X_test_final = test_final.drop(columns=[\"label\"])\n",
    "y_test_final = test_final[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 34), (80,), (55, 34), (55,), (45, 34), (45,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bal.shape, y_train_bal.shape, X_train_imb.shape, y_train_imb.shape, X_test_final.shape, y_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 0    40\n",
       " 1    40\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 0    40\n",
       " 1    15\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 0    43\n",
       " 1     2\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bal.value_counts(), y_train_imb.value_counts(), y_test_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import solve\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "# from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.sparse.linalg import cg\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REWKLR(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Rare Event Weighted Kernel Logistic Regression (RE-WKLR) implementation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float, default=1.0\n",
    "        Kernel bandwidth parameter for RBF kernel.\n",
    "    lambda_ : float, default=0.1\n",
    "        Regularization parameter.\n",
    "    w1 : float, default=None\n",
    "        Weight for positive class (rare events). If None, will be calculated from data.\n",
    "    w0 : float, default=None\n",
    "        Weight for negative class. If None, will be calculated from data.\n",
    "    max_iter : int, default=30\n",
    "        Maximum number of IRLS iterations.\n",
    "    max_cg_iter : int, default=200\n",
    "        Maximum number of conjugate gradient iterations.\n",
    "    tol : float, default=1e-4\n",
    "        Tolerance for stopping criterion.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma, lambda_, tau, w1=None, w0=None, \n",
    "                 max_iter=30, max_cg_iter=200, tol1=2.5, tol2=0.005):\n",
    "        self.sigma = sigma\n",
    "        self.lambda_ = lambda_\n",
    "        self.w1 = w1\n",
    "        self.w0 = w0\n",
    "        self.max_iter = max_iter\n",
    "        self.max_cg_iter = max_cg_iter\n",
    "        self.tol1 = tol1\n",
    "        self.tol2 = tol2\n",
    "        self.tau = tau\n",
    "\n",
    "    \n",
    "    def rbf_kernel(self, X1, X2):\n",
    "        sq_dists = cdist(X1, X2, 'sqeuclidean')\n",
    "        return np.exp(-sq_dists / (2 * self.sigma ** 2))\n",
    "    \n",
    "    def logistic(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def loglikelihood(self, K, alpha, y, w):\n",
    "        eta = K @ alpha\n",
    "        # Regularization term: (lambda/2) * alpha^T K alpha\n",
    "        reg = (self.lambda_ / 2) * alpha.T @ K @ alpha\n",
    "        # Weighted log-likelihood: sum w_i [y_i eta_i - log(1 + exp(eta_i))]\n",
    "        ll = np.sum(w * (y * eta - np.log1p(np.exp(eta))))\n",
    "        return ll - reg\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the RE-WKLR model to the training data.\"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # tau = 0.40 # Population proportion \n",
    "        y_bar = np.mean(y)  # Sample proportion\n",
    "        self.w1 = self.tau / y_bar if y_bar > 0 else 1.0\n",
    "        self.w0 = (1 - self.tau) / (1 - y_bar) if y_bar < 1 else 1.0\n",
    "    \n",
    "        # # Calculate weights if not provided\n",
    "        # if self.w1 is None or self.w0 is None:\n",
    "        #     tau = 0.6 # Population proportion \n",
    "        #     y_bar = np.mean(y)  # Sample proportion\n",
    "        #     self.w1_ = tau / y_bar if y_bar > 0 else 1.0\n",
    "        #     self.w0_ = (1 - tau) / (1 - y_bar) if y_bar < 1 else 1.0\n",
    "        # else:\n",
    "        #     self.w1_ = self.w1\n",
    "        #     self.w0_ = self.w0\n",
    "        # print(f\"w1: {self.w1}, w0: {self.w0}\")\n",
    "        # Compute kernel matrix\n",
    "        self.X_train_ = X\n",
    "        K = self.rbf_kernel(X, X)\n",
    "        \n",
    "        # Add small constant to diagonal for numerical stability\n",
    "        K = K + 1e-8 * np.eye(n_samples)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        alphainit = np.zeros(n_samples)\n",
    "        # delta = float('inf')\n",
    "        # delta = 1.0\n",
    "        # c = 0\n",
    "        # LLW = 0\n",
    "        alpha = np.zeros_like(alphainit)\n",
    "        bias = np.zeros_like(alphainit)\n",
    "        \n",
    "        # IRLS iterations\n",
    "        # while delta > self.tol1 and c < self.max_iter:\n",
    "        \n",
    "        for c in range(self.max_iter):\n",
    "            \n",
    "            # Compute probabilities\n",
    "            p = self.logistic(K @ alphainit)\n",
    "            \n",
    "            # Compute variance\n",
    "            v = p * (1 - p)\n",
    "            \n",
    "            # Compute weights\n",
    "            w = np.where(y == 1, self.w1, self.w0)\n",
    "            \n",
    "            # Compute adjusted response\n",
    "            z = K @ alphainit + (y - p) / v\n",
    "            \n",
    "            # Compute weighted logit elements\n",
    "            Q = 1 / (v * w)\n",
    "            \n",
    "            # Compute the bias response\n",
    "            xi = 0.35 * Q * ((1 + self.w1) * p - self.w1)\n",
    "            \n",
    "            # Obtain the nxn diagonal weight matrix\n",
    "            D = np.diag(v * w)\n",
    "            \n",
    "            # Compute alpha and bias using CG\n",
    "            A = K.T @ D @ K + self.lambda_ * K\n",
    "            b_alpha = K.T @ D @ z\n",
    "            b_bias = K.T @ D @ xi\n",
    "            \n",
    "            # Solve for alpha using CG\n",
    "            alpha = cg(A, b_alpha, maxiter=self.max_cg_iter, rtol=self.tol2)[0]\n",
    "            \n",
    "            # Solve for bias using CG\n",
    "            bias = cg(A, b_bias, maxiter=self.max_cg_iter, rtol=self.tol2)[0]\n",
    "\n",
    "            \n",
    "            # Given current alpha, compute the new probabilities\n",
    "            p = self.logistic(K @ alpha)\n",
    "            alphainit = alpha\n",
    "            \n",
    "            # LLOld = LLW\n",
    "            # LLW = -2 * self.loglikelihood(K, alpha, y, w)\n",
    "            \n",
    "            # # Check convergence\n",
    "            # if c > 0:\n",
    "            #     delta = np.abs((LLOld - LLW) / LLW )\n",
    "            #     print(f\"Iteration {c}: Log-likelihood = {LLW:.4f}, Delta = {delta:.4f}\")\n",
    "                \n",
    "                \n",
    "            # LLOld = LLW\n",
    "            # LLW = -2 * self.loglikelihood(K, alpha, y, w)\n",
    "            # delta = np.abs((LLOld - LLW) / LLW )\n",
    "            \n",
    "            # c += 1\n",
    "            \n",
    "            if c > 0:\n",
    "                deviance = -2 * self.loglikelihood(K, alpha, y, w)\n",
    "                dev_diff = np.abs((prev_deviance - deviance)/deviance)\n",
    "                print(f\"Deviance: {deviance:.4f}, Change: {dev_diff:.4f}\")\n",
    "                if dev_diff < self.tol1:\n",
    "                    break\n",
    "            prev_deviance = -2 * self.loglikelihood(K, alpha, y, w)\n",
    "            \n",
    "        # print(f\"Iteration {c}: Log-likelihood = {LLW:.4f}, Delta = {delta:.4f}\")\n",
    "        \n",
    "        # Check convergence    \n",
    "        # if verbose:\n",
    "        #     if delta < self.tol1:\n",
    "        #         print(f\"Converged after {c} iterations.\")\n",
    "        #     else:\n",
    "        #         print(f\"Max iterations reached: {self.max_iter}.\")\n",
    "                \n",
    "        # Compute the unbiased alpha\n",
    "        unbiased_alpha = alpha - bias\n",
    "        \n",
    "        # Compute the optimal probabilities\n",
    "        probunbiased = self.logistic(K @ unbiased_alpha)\n",
    "        \n",
    "        self.alpha_ = unbiased_alpha    \n",
    "        self.prob_ = probunbiased\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        \"\"\"Predict probabilities for the input data.\"\"\"\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        \n",
    "        K_test = self.rbf_kernel(X, self.X_train_)\n",
    "        prob = self.logistic(K_test @ self.alpha_)\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for the input data.\"\"\"\n",
    "        prob = self.predict_prob(X)\n",
    "        return (prob >= 0.5).astype(int)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:44.378431Z",
     "iopub.status.busy": "2025-04-18T08:08:44.378065Z",
     "iopub.status.idle": "2025-04-18T08:08:44.409300Z",
     "shell.execute_reply": "2025-04-18T08:08:44.407933Z",
     "shell.execute_reply.started": "2025-04-18T08:08:44.378402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Create and fit RE-WKLR model\n",
    "# model = REWKLR(sigma=2.5, lambda_=0.07)\n",
    "# model.fit(X_train_bal, y_train_bal, verbose=True)\n",
    "\n",
    "# # Evaluate\n",
    "# y_pred = model.predict(X_test_final)\n",
    "# print(classification_report(y_test_final, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class distribution of y_pred and y_test_final\n",
    "# print(\"Predicted class distribution:\")\n",
    "# print(pd.Series(y_pred).value_counts())\n",
    "# print(\"\\nTrue class distribution:\")\n",
    "# print(pd.Series(y_test_final).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:44.410486Z",
     "iopub.status.busy": "2025-04-18T08:08:44.410166Z",
     "iopub.status.idle": "2025-04-18T08:08:44.416896Z",
     "shell.execute_reply": "2025-04-18T08:08:44.415776Z",
     "shell.execute_reply.started": "2025-04-18T08:08:44.410457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# #Calculate accuracy\n",
    "# accuracy = accuracy_score(y_test_final, y_pred)\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:44.418110Z",
     "iopub.status.busy": "2025-04-18T08:08:44.417808Z",
     "iopub.status.idle": "2025-04-18T08:08:44.435887Z",
     "shell.execute_reply": "2025-04-18T08:08:44.434792Z",
     "shell.execute_reply.started": "2025-04-18T08:08:44.418077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_tuning(X_train_, y_train_, X_test_, y_test_, tau_vals, lambda_vals, sigma_vals, dataset_name=\"default\"):\n",
    "    \"\"\"\n",
    "    Tune hyperparameters (σ, λ) using bootstrap applied to the TEST SET.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics.pairwise import rbf_kernel\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    from sklearn.utils import resample\n",
    "\n",
    "    # Set number of bootstrap rounds (B)\n",
    "    B = 200 if dataset_name.lower() in [\"spam\", \"tornado\"] else 5000\n",
    "\n",
    "    best_acc = 0\n",
    "    best_lambda = None\n",
    "    best_sigma = None\n",
    "    best_tau = None\n",
    "\n",
    "    # Loop over λ and σ combinations\n",
    "    for tau, lambda_, sigma in itertools.product(tau_vals, lambda_vals, sigma_vals):\n",
    "\n",
    "        # Train model on the training data\n",
    "        model = REWKLR(sigma=sigma, lambda_=lambda_, tau=tau)\n",
    "        model.fit(X_train_,y_train_)\n",
    "\n",
    "\n",
    "        # Track per-class accuracies for each bootstrap round\n",
    "        class_1_acc = []\n",
    "        class_0_acc = []\n",
    "\n",
    "        \n",
    "        for _ in range(B):\n",
    "            X_sample, y_sample = resample(X_test_, y_test_, replace=True, n_samples=len(X_test_))\n",
    "            \n",
    "            # Compute predictions for the bootstrap sample\n",
    "            y_pred_sample= model.predict(X_sample)\n",
    "\n",
    "\n",
    "            # Track TP, TN, FP, FN for this bootstrap sample\n",
    "            tn, fp, fn, tp = confusion_matrix(y_sample, y_pred_sample, labels=[0, 1]).ravel()\n",
    "\n",
    "            # Class 1 accuracy (TP rate) & Class 0 accuracy (TN rate)\n",
    "            a1_r = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            a0_r = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "            class_1_acc.append(a1_r)\n",
    "            class_0_acc.append(a0_r)\n",
    "\n",
    "        #  Compute average accuracies per class across all bootstrap samples\n",
    "        a1_avg = np.mean(class_1_acc)\n",
    "        a0_avg = np.mean(class_0_acc)\n",
    "\n",
    "        #  Compute final accuracy for this combination (A = min{a1_avg, a0_avg})\n",
    "        A = min(a1_avg, a0_avg)\n",
    "\n",
    "        print(f\"tau = {tau}, λ = {lambda_}, σ = {sigma}, Final Accuracy A = {A:.4f}\")\n",
    "\n",
    "        # Track the best combination (A* = max{A})\n",
    "        if A > best_acc:\n",
    "            best_acc = A\n",
    "            best_tau = tau\n",
    "            best_lambda = lambda_\n",
    "            best_sigma = sigma\n",
    "            \n",
    "\n",
    "    # Return the best combination of (λ, σ) with max A*\n",
    "    print(\n",
    "        f\"Best combination: tau = {best_tau}, λ = {best_lambda}, σ = {best_sigma}, Final Accuracy A* = {best_acc:.4f}\"\n",
    "    )\n",
    "    return best_tau, best_lambda, best_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:08:44.437376Z",
     "iopub.status.busy": "2025-04-18T08:08:44.437037Z",
     "iopub.status.idle": "2025-04-18T08:08:44.457331Z",
     "shell.execute_reply": "2025-04-18T08:08:44.456304Z",
     "shell.execute_reply.started": "2025-04-18T08:08:44.437347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance: 8.4489, Change: 1.0307\n",
      "tau = 0.379, λ = 0.007, σ = 7, Final Accuracy A = 0.0000\n",
      "Best combination: tau = None, λ = None, σ = None, Final Accuracy A* = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# tau_range = np.arange(0.30, 0.32, 0.01)\n",
    "tau_range = [0.379]\n",
    "sigma_range = [7]\n",
    "lambda_range = [0.007]\n",
    "best_tau, best_lambda, best_sigma = bootstrap_tuning(X_train_imb, y_train_imb, X_test_final, y_test_final, tau_range, lambda_range, sigma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance: 32.1720, Change: 0.1627\n",
      "tau = 0.379, λ = 0.07, σ = 2.5, Final Accuracy A = 0.8722\n",
      "Best combination: tau = 0.379, λ = 0.07, σ = 2.5, Final Accuracy A* = 0.8722\n"
     ]
    }
   ],
   "source": [
    "sigma_bal = [2.5]\n",
    "lambda_bal = [0.07]\n",
    "best_tau_bal, best_lambda_bal, best_sigma_bal = bootstrap_tuning(X_train_bal, y_train_bal, X_test_final, y_test_final, tau_range, lambda_bal, sigma_bal)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6880881,
     "sourceId": 11046079,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d881c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import solve\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.sparse.linalg import cg\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec943e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class REWKLR(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Rare Event Weighted Kernel Logistic Regression (RE-WKLR) implementation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float, default=1.0\n",
    "        Kernel bandwidth parameter for RBF kernel.\n",
    "    lambda_ : float, default=0.1\n",
    "        Regularization parameter.\n",
    "    w1 : float, default=None\n",
    "        Weight for positive class (rare events). If None, will be calculated from data.\n",
    "    w0 : float, default=None\n",
    "        Weight for negative class. If None, will be calculated from data.\n",
    "    max_iter : int, default=30\n",
    "        Maximum number of IRLS iterations.\n",
    "    max_cg_iter : int, default=200\n",
    "        Maximum number of conjugate gradient iterations.\n",
    "    tol : float, default=1e-4\n",
    "        Tolerance for stopping criterion.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma, lambda_, w1=None, w0=None, \n",
    "                 max_iter=30, max_cg_iter=200, tol1=2.5, tol2=0.005):\n",
    "        self.sigma = sigma\n",
    "        self.lambda_ = lambda_\n",
    "        self.w1 = w1\n",
    "        self.w0 = w0\n",
    "        self.max_iter = max_iter\n",
    "        self.max_cg_iter = max_cg_iter\n",
    "        self.tol1 = tol1\n",
    "        self.tol2 = tol2\n",
    "    \n",
    "    # def _rbf_kernel(self, X1, X2):\n",
    "    #     \"\"\"Compute RBF kernel matrix between X1 and X2.\"\"\"\n",
    "    #     sq_dist = np.sum(X1**2, axis=1).reshape(-1, 1) + \\\n",
    "    #               np.sum(X2**2, axis=1) - 2 * np.dot(X1, X2.T)\n",
    "    #     return np.exp(-0.5 * sq_dist / self.sigma**2)\n",
    "    \n",
    "    def _logistic(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _loglikelihood(self, K, alpha, y, w):\n",
    "        eta = K @ alpha\n",
    "        reg = (self.lambda_ / 2) * alpha.T @ K @ alpha\n",
    "        ll = 0\n",
    "        for i in range(len(y)):\n",
    "            num = np.exp(y[i] * eta[i])\n",
    "            denom = 1 + np.exp(eta[i])\n",
    "            ll += w[i] * np.log(num / denom)\n",
    "        return ll - reg\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, verbose=False):\n",
    "        \"\"\"Fit the RE-WKLR model to the training data.\"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Calculate weights if not provided\n",
    "        if self.w1 is None or self.w0 is None:\n",
    "            tau = 0.6 # Population proportion \n",
    "            y_bar = np.mean(y)  # Sample proportion\n",
    "            self.w1_ = tau / y_bar if y_bar > 0 else 1.0\n",
    "            self.w0_ = (1 - tau) / (1 - y_bar) if y_bar < 1 else 1.0\n",
    "        else:\n",
    "            self.w1_ = self.w1\n",
    "            self.w0_ = self.w0\n",
    "        \n",
    "        # Compute kernel matrix\n",
    "        self.X_train_ = X\n",
    "        K = rbf_kernel(X, X)\n",
    "        \n",
    "        # Add small constant to diagonal for numerical stability\n",
    "        K_hat = K + 1e-8 * np.eye(n_samples)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        alphainit = np.zeros(n_samples)\n",
    "        p = self.logistic(K @ alphainit)\n",
    "        delta = 5.0\n",
    "        i = 0\n",
    "        LLW = 0.0\n",
    "        alpha = np.zeros_like(alphainit)\n",
    "        bias = np.zeros_like(alphainit)\n",
    "        w = np.where(y == 1, self.w1_, self.w0_)\n",
    "        \n",
    "        \n",
    "        # IRLS iterations\n",
    "        while delta > self.tol1 and i < self.max_iter:\n",
    "            # Compute probabilities\n",
    "            eta = K @ alphainit\n",
    "            # reg = (self.lambda_ / 2) * alpha.T @ K @ alpha\n",
    "            # p = 1 / (1 + np.exp(-eta))\n",
    "            \n",
    "            # Compute weights and adjusted response\n",
    "            v = p * (1 - p)\n",
    "            # w = np.where(y == 1, self.w1_, self.w0_)\n",
    "            \n",
    "            z = eta + (y - p) / v\n",
    "            \n",
    "            # Compute Q matrix diagonal elements\n",
    "            Q_diag = 1 / (v * w)\n",
    "            \n",
    "            # Compute bias correction terms\n",
    "            xi = 0.5 * Q_diag * ((1 + self.w1_) * p - self.w1_)\n",
    "            \n",
    "            D = np.diag(v * w)\n",
    "            \n",
    "            # Solve for alpha using CG\n",
    "            A = K_hat.T @ D @ K_hat + self.lambda_ * K_hat\n",
    "            b_alpha = K_hat.T @ D @ z\n",
    "            b_bias = K_hat.T @ D @ xi\n",
    "            \n",
    "            alpha = cg(A, b_alpha, x0=alpha, maxiter=self.max_cg_iter, rtol=self.tol2)[0]\n",
    "            \n",
    "            # alpha = self._conjugate_gradient(A, b_alpha, alpha, \n",
    "            #                                self.max_cg_iter, self.tol2)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # # Solve for bias using CG\n",
    "            \n",
    "            bias = cg(A, b_bias, x0=bias, maxiter=self.max_cg_iter, rtol=self.tol2)[0]\n",
    "            # bias = self._conjugate_gradient(A, b_bias, np.zeros_like(alpha), \n",
    "            #                               self.max_cg_iter, self.tol2)\n",
    "            \n",
    "        \n",
    "            \n",
    "            # Given current alpha, compute the new eta\n",
    "            eta = K @ alpha\n",
    "            p = self.logistic(eta)\n",
    "            alphainit = alpha.copy()\n",
    "            \n",
    "            LLOld = LLW\n",
    "            LLW = -2 * self._loglikelihood(K, alpha, y, w)\n",
    "            delta = np.abs((LLOld - LLW) / LLW + 1e-8)\n",
    "            i += 1\n",
    "            \n",
    "        if verbose:\n",
    "            if delta < self.tol1:\n",
    "                print(f\"Converged after {i} iterations.\")\n",
    "            else:\n",
    "                print(f\"Max iterations reached: {self.max_iter}.\")\n",
    "                \n",
    "        \n",
    "        unbiased_alpha = alpha - bias\n",
    "        probunbiased = self.logistic(K @ unbiased_alpha)\n",
    "        self.alpha_ = unbiased_alpha    \n",
    "        self.prob_ = probunbiased\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        \"\"\"Predict probabilities for the input data.\"\"\"\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        \n",
    "        K_test = rbf_kernel(X, self.X_train_)\n",
    "        prob = self.logistic(K_test @ self.alpha_)\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for the input data.\"\"\"\n",
    "        prob = self.predict_prob(X)\n",
    "        return (prob >= 0.5).astype(int)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b08b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
